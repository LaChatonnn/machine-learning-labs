{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5_rf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+DxyjmtFcRwBDUXxX7VCl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YipingNUS/machine-learning-labs/blob/master/lab5_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cICK2yum_YeR",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Regression for California Housing Price Prediction\n",
        "\n",
        "In this lab, you'll build a random forest model for another dataset that's available in sklearn. You can refer to the manual [here](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset).\n",
        "\n",
        "Your task is as follows:\n",
        "\n",
        "1. Explore the dataset like we did in lab 2.\n",
        "2. Train a [random forest regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) on the dataset and report the mean squared error on log-scale. \n",
        "3. Compute the feature importance ([reference](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py)) and see if you can use it to achieve the same performance with fewer features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2KYbmppXnRV",
        "colab_type": "text"
      },
      "source": [
        "**Side note:** the reason I let you take the log-scale of the target value is once in the log-scale, the absolute difference becomes the percentage difference:\n",
        "\n",
        "```\n",
        "import math\n",
        "print(math.log(100)- math.log(90))\n",
        "print(math.log(10)- math.log(9))\n",
        "> 0.10536051565782678\n",
        "> 0.10536051565782634\n",
        "```\n",
        "\n",
        "I find the percentage error makes more sense since it ignores the magnitude of the original data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H97cp-ty8612",
        "colab_type": "code",
        "outputId": "d3d41b4d-baac-4e70-9444-aa563b1d56bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K20AZWmy_CLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO: your code here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}